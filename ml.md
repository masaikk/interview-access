# 百面机器学习



## 特征工程

### 数据归一化的意义？$\bigstar$

对于两个范围不同的变量来说，把它们的变化范围拉到相似的范围，在梯度下降的时候更容易找到最优解。

### word2vec $\bigstar \bigstar$

分为**CBOW**和**Skip-gram**

CBOW是将上下文的词语来预测当前词，Skip-gram是当前词来预测上下文各词的概率。

在输入层中，总共N个不同的单词转化为N个独热向量表示。在隐含层中，有K个隐含单元，所以权重矩阵N\*K。输出层矩阵K\*N，之后连接softmax层。

softmax公式
$$
P(y=w_n|x)=\frac{e^{x_n}}{\sum\limits_{k=1}^{N}e^{x_{k}}}
$$
一个词为N维原始输入向量，x表示为一个N维的输出向量，$x_{n}$表示为在原始输出向量中，与单词$w_{n}$对应维度的取值。

## 模型评估

### 评估指标的局限性$ \bigstar$

准确率$accuracy=\frac{被正确分类的样本个数}{总样本个数}$。这种导致在不同类的样本比例不平均的时候，占比大的样本更加能影响准确率。小比例的类别，就算全部预测错误，对总体准确率也影响不大。

召回率$recall=\frac{分类正确的正样本个数}{全部正样本个数}$

只用某个点对应的精准率和召回率是不能完全地衡量模型的性能，只能通过P-R曲线的整体表现来判断。此外，F1 score和ROC曲线也可以反映一个排序模型的性能。


$$
F1=\frac{2*accuracy*recall}{accuracy+recall}
$$


较大的错误值可能会导致总体平方根误差变得很大，其中，平方根误差为$RMSE=\sqrt{\frac{\sum\limits_{i=1}^{n}{(第i个样本点真实值-第i个样本点预测值)^2}}{n}}$

这种计算方法如果存在严重的离群点，会被严重影响。解决办法有三：

+ 把这些点当作噪声忽略掉

+ 如果不考虑这些是噪声点，就应该对这些点重新机制建模

+ 使用更合适的指标，比如评价绝对百分比误差MAPE(mean absolute percent error)

  
  $$
  MAPE=\sum\limits_{i=1}^{n}{\abs{\frac{第i个样本点真实值-第i个样本点预测值}{第i个样本点真实值}}*{\frac{100}{n}}}
  $$
  

  这里相当于把每个点都进行了归一化操作。

